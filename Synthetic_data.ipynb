{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import nibabel as nib\n",
    "import random\n",
    "\n",
    "def generate_3d_volume(image_size, radius, center_sphere):\n",
    "    # Create a 3D grid\n",
    "    x = np.linspace(0, 1, image_size[0])\n",
    "    y = np.linspace(0, 1, image_size[1])\n",
    "    z = np.linspace(0, 1, image_size[2])\n",
    "    x, y, z = np.meshgrid(x, y, z, indexing='ij')  # Ensure correct indexing for the grid\n",
    "\n",
    "    # Sphere mask using the fixed radius and center position\n",
    "    sphere_mask = ((x - center_sphere[0])**2 + (y - center_sphere[1])**2 + (z - center_sphere[2])**2) < (radius / image_size[0])**2\n",
    "\n",
    "\n",
    "    # Initialize volume with grey for background\n",
    "    volume = np.full(image_size, 255)  # Set entire volume to grey\n",
    "\n",
    "    # Set the sphere to white\n",
    "    volume[sphere_mask] = 128  # Make the sphere white\n",
    "\n",
    "    return volume\n",
    "\n",
    "# Parameters\n",
    "image_size = (16, 16, 16)  # Example size of the 3D volume, adjusted for practicality\n",
    "radius = 4  # Example radius, scaled to the example volume size\n",
    "num_samples = 1000  # Number of samples for demonstration\n",
    "\n",
    "volumes = []\n",
    "for i in range(num_samples):\n",
    "    # Generate a random center for the sphere within the volume\n",
    "    sphere_center = (\n",
    "        random.uniform(radius / image_size[0], 1 - radius / image_size[0]),\n",
    "        random.uniform(radius / image_size[1], 1 - radius / image_size[1]),\n",
    "        random.uniform(radius / image_size[2], 1 - radius / image_size[2])\n",
    "        )\n",
    "\n",
    "    # Generate 3D volume\n",
    "    volume = generate_3d_volume(image_size, radius, sphere_center)\n",
    "    volumes.append(volume)\n",
    "    \n",
    "# Save all volumes in a single numpy file\n",
    "# Saving the generated volumes to a .npz file\n",
    "np.savez('synthetic_dataset.npz', *volumes)\n",
    "\n",
    "# Example of saving one volume to a NIfTI file (for demonstration)\n",
    "nifti_image = nib.Nifti1Image(volumes[0].astype(np.float32), np.eye(4))\n",
    "nifti_file_path = 'input.nii.gz'\n",
    "nib.save(nifti_image, nifti_file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "import shutil\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Conv3D, MaxPooling3D, Conv3DTranspose, BatchNormalization\n",
    "from tensorflow.keras.callbacks import TensorBoard, Callback\n",
    "import h5py\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import pdb\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from tqdm.keras import TqdmCallback\n",
    "\n",
    "\n",
    "\n",
    "# Load your npz file\n",
    "loaded_data = np.load('synthetic_dataset.npz')\n",
    "num_samples = len(loaded_data.files)\n",
    "sample_fraction = 1\n",
    "num_samples_to_use = int(num_samples * sample_fraction)\n",
    "\n",
    "\n",
    "# Use the loaded_data dictionary to get the volumes\n",
    "train_x = np.array([loaded_data[f'arr_{i}'] for i in range(num_samples_to_use)])\n",
    "print(list(set([np.max(train_x[i]) for i in range(len(train_x))])))\n",
    "print(train_x.shape)\n",
    "# exit(1)\n",
    "\n",
    "# Reshape train_x to add a channel dimension, assuming grayscale images so only 1 channel is added\n",
    "train_x = np.expand_dims(train_x, axis=-1)\n",
    "print(\"New train_x shape with channel dimension:\", train_x.shape)\n",
    "\n",
    "# Define autoencoder architecture\n",
    "def define_autoencoder(input_shape):\n",
    "\n",
    "    input_layer = Input(shape=input_shape)\n",
    "    # print('input_shape in auto encoder',input_shape)\n",
    "    \n",
    "    # Encoder\n",
    "    encoder = Conv3D(64, kernel_size=(3, 3, 3), activation='relu', padding='same')(input_layer)\n",
    "    print('####encoder###',encoder)\n",
    "    # exit(1)\n",
    "    \n",
    "    encoder = BatchNormalization()(encoder)\n",
    "    encoder = MaxPooling3D(pool_size=(2, 2, 2), padding='same')(encoder)\n",
    "    \n",
    "    print('####encoder###',encoder)\n",
    "    \n",
    "    \n",
    "    encoder = Conv3D(128, kernel_size=(3, 3, 3), activation='relu', padding='same')(encoder)\n",
    "    print('####encoder###',encoder)\n",
    "    \n",
    "    encoder = BatchNormalization()(encoder)\n",
    "    encoder = MaxPooling3D(pool_size=(2, 2, 2), padding='same')(encoder)\n",
    "    # print('####encoder###',encoder)\n",
    "    print('####output_layer###',encoder.shape)\n",
    "    \n",
    "    \n",
    "    \n",
    "    # Decoder\n",
    "    decoder = Conv3DTranspose(128, kernel_size=(3, 3, 3), activation='relu', padding='same')(encoder)\n",
    "    decoder = BatchNormalization()(decoder)\n",
    "    decoder = tf.keras.layers.UpSampling3D(size=(2, 2, 2))(decoder)\n",
    "    print('####output_layer###',decoder.shape)\n",
    "    \n",
    "    \n",
    "    \n",
    "    decoder = Conv3DTranspose(64, kernel_size=(3, 3, 3), activation='relu', padding='same')(decoder)\n",
    "    decoder = BatchNormalization()(decoder)\n",
    "    decoder = tf.keras.layers.UpSampling3D(size=(2, 2, 2))(decoder)\n",
    "    \n",
    "    print('####output_layer###',decoder.shape)\n",
    "    \n",
    "    \n",
    "    # Output layer with the same number of channels as input data\n",
    "    output_layer = Conv3D(1, kernel_size=(3, 3, 3), activation='sigmoid', padding='same')(decoder)\n",
    "    output_layer = output_layer * 255\n",
    "    print('####output_layer###',output_layer.shape)\n",
    "    \n",
    "    \n",
    "    \n",
    "    autoencoder = Model(inputs=input_layer, outputs=output_layer)\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "    autoencoder.compile(optimizer= optimizer, loss= tf.keras.losses.MeanSquaredError())  # Adjust loss function if needed\n",
    "    \n",
    "    # print('####autoencoder###',autoencoder)\n",
    "    \n",
    "    return autoencoder\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Instantiate and compile autoencoder\n",
    "input_shape = train_x.shape[1:]\n",
    "print(\"the last input shape\", train_x.shape[1:])\n",
    "\n",
    "autoencoder = define_autoencoder(input_shape)\n",
    "\n",
    "# Create a tf.data.Dataset from the numpy array\n",
    "dataset = tf.data.Dataset.from_tensor_slices(train_x)  # Changed line\n",
    "batch_size = 10  # Added line\n",
    "dataset = dataset.shuffle(buffer_size=1000).batch(batch_size)  # Changed line\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Train the autoencoder using the dataset\n",
    "autoencoder.fit(dataset.map(lambda x: (x, x)), epochs=100)  # Changed line\n",
    "\n",
    "autoencoder.save('autoencoder_model.h5')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "autoencoder = tf.keras.models.load_model('autoencoder_model.h5')\n",
    "\n",
    "    \n",
    "print(train_x[2].shape)\n",
    "# validation_data\n",
    "\n",
    "decoded_imgs = autoencoder.predict(train_x)\n",
    "# Assuming custom_dataset and autoencoder are defined\n",
    "for i in range(1):\n",
    "    # Visualize first three volumes\n",
    "    input_volume = train_x[i]\n",
    "    \n",
    "    reconstructed_volume = decoded_imgs[i]\n",
    "        # Convert the numpy array to a NIfTI image\n",
    "    nifti_image = nib.Nifti1Image(reconstructed_volume, np.eye(4))\n",
    "\n",
    "    # Save the NIfTI image to a file\n",
    "    nifti_file_path = 'rec.nii.gz'\n",
    "    nib.save(nifti_image, nifti_file_path)\n",
    "   "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "p120",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
